{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210119_tf20_기본사항_즉시실행",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxErqyjnTIQFpIo7FUzO4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyt50207/StudyML/blob/main/210119_tf20_%EA%B8%B0%EB%B3%B8%EC%82%AC%ED%95%AD_%EC%A6%89%EC%8B%9C%EC%8B%A4%ED%96%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MF6BP6sIOOg"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "import cProfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTInmDIQJJqp"
      },
      "source": [
        "tf.executing_eagerly()\r\n",
        "\r\n",
        "X= [[2.]]\r\n",
        "m=tf.matmul(X,X)\r\n",
        "print(\"hello,{}\".format(m))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYT7HTh5JQyv"
      },
      "source": [
        "a= tf.constant([[1,2],\r\n",
        "                [3,4]])\r\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7g7rmlkKlut"
      },
      "source": [
        "tf.add(a,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6DOasiKKtNO"
      },
      "source": [
        "c= tf.constant([[1,1]])\r\n",
        "tf.add(a,c)                        #브로드캐스팅 작업 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWPaTcAuKzOv"
      },
      "source": [
        "b= tf.add(a,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQp9ucQLJ84"
      },
      "source": [
        "print(a*b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PqRNhKxLMpo"
      },
      "source": [
        "#Numpy 값 사용\r\n",
        "import numpy as np\r\n",
        "c= np.multiply(a,b)\r\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb1TT9zlLduI"
      },
      "source": [
        "#텐서로부터 얻어오기\r\n",
        "a.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzgywKYGNxf9"
      },
      "source": [
        "def fizzbuzz(max_num):\r\n",
        "  counter = tf.constant(0)\r\n",
        "  max_num = tf.convert_to_tensor(max_num)\r\n",
        "  for num in range(1, max_num.numpy()+1):\r\n",
        "    num = tf.constant(num)\r\n",
        "    if int(num % 3) == 0 and int(num % 5) == 0:\r\n",
        "      print('FizzBuzz')\r\n",
        "    elif int(num % 3) == 0:\r\n",
        "      print('Fizz')\r\n",
        "    elif int(num % 5) == 0:\r\n",
        "      print('Buzz')\r\n",
        "    else:\r\n",
        "      print(num.numpy())\r\n",
        "    counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ykZU9sPNyY9"
      },
      "source": [
        "fizzbuzz(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WcGg9JZN7Hs"
      },
      "source": [
        "w = tf.Variable([[1.0]])\r\n",
        "with tf.GradientTape() as tape: #함수처럼 구현\r\n",
        "  loss = w * w* w\r\n",
        "\r\n",
        "grad = tape.gradient(loss, w)\r\n",
        "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqjaLVfCVoGz"
      },
      "source": [
        "모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWfWXWd6Vq2T"
      },
      "source": [
        "# mnist 데이터 가져오기 및 포맷 맞추기\r\n",
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\r\n",
        "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\r\n",
        "   tf.cast(mnist_labels,tf.int64)))\r\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB4T2EpDVuHU"
      },
      "source": [
        "mnist_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ggxjOxWvMD"
      },
      "source": [
        "a= mnist_images[...,tf.newaxis] #tf.newaxis는 새로운 축을만들때 이용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr2dZwQ6W5pO"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17IslEMqW990"
      },
      "source": [
        "mnist_images[tf.newaxis,:,:,:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YClDs_bXXMCt"
      },
      "source": [
        "mnist_images[:,tf.newaxis,:,:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkRhETp2Xeqe"
      },
      "source": [
        "# 모델 생성\r\n",
        "mnist_model = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\r\n",
        "                         input_shape=(None, None, 1)),\r\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\r\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "  tf.keras.layers.Dense(10)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zgqvfKcYt-D"
      },
      "source": [
        "for images,labels in dataset.take(1):\r\n",
        "  print(\"로짓: \", mnist_model(images[0:1]).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6mnIsCZYv9r"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "\r\n",
        "loss_history = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGXfYLPyZQQj"
      },
      "source": [
        "def train_step(images, labels):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    logits = mnist_model(images, training=True)\r\n",
        "\r\n",
        "    # 결과의 형태를 확인하기 위해서 단언문 추가\r\n",
        "    tf.debugging.assert_equal(logits.shape, (32, 10))\r\n",
        "\r\n",
        "    loss_value = loss_object(labels, logits)\r\n",
        "\r\n",
        "  loss_history.append(loss_value.numpy().mean())\r\n",
        "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\r\n",
        "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))\r\n",
        "\r\n",
        "def train():\r\n",
        "  for epoch in range(3):\r\n",
        "    for (batch, (images, labels)) in enumerate(dataset):\r\n",
        "      train_step(images, labels)\r\n",
        "    print ('에포크 {} 종료'.format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P3fDmqEZTFS"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCqwa_WaZcV8"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(loss_history)\r\n",
        "plt.xlabel('Batch #')\r\n",
        "plt.ylabel('Loss [entropy]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y60BUFkPZkuJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCCkET28Z0d8"
      },
      "source": [
        "변수와 옵티마이저"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT3mwyTSZ2aO"
      },
      "source": [
        "class Model(tf.keras.Model):\r\n",
        "  def __init__(self):\r\n",
        "    super(Model, self).__init__()\r\n",
        "    self.W = tf.Variable(5., name='weight')\r\n",
        "    self.B = tf.Variable(10., name='bias')\r\n",
        "  def call(self, inputs):\r\n",
        "    return inputs * self.W + self.B\r\n",
        "\r\n",
        "# 약 3 * x + 2개의 점으로 구성된 실험 데이터\r\n",
        "NUM_EXAMPLES = 2000\r\n",
        "training_inputs = tf.random.normal([NUM_EXAMPLES])\r\n",
        "noise = tf.random.normal([NUM_EXAMPLES])\r\n",
        "training_outputs = training_inputs * 3 + 2 + noise\r\n",
        "\r\n",
        "# 최적화할 손실함수\r\n",
        "def loss(model, inputs, targets):\r\n",
        "  error = model(inputs) - targets\r\n",
        "  return tf.reduce_mean(tf.square(error))  #rmse만드는 함수\r\n",
        "\r\n",
        "def grad(model, inputs, targets):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    loss_value = loss(model, inputs, targets)\r\n",
        "  return tape.gradient(loss_value, [model.W, model.B])\r\n",
        "\r\n",
        "# 정의:\r\n",
        "# 1. 모델\r\n",
        "# 2. 모델 파라미터에 대한 손실 함수의 미분\r\n",
        "# 3. 미분에 기초한 변수 업데이트 전략\r\n",
        "model = Model()\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\r\n",
        "\r\n",
        "print(\"초기 손실: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\r\n",
        "\r\n",
        "# 반복 훈련\r\n",
        "for i in range(300):\r\n",
        "  grads = grad(model, training_inputs, training_outputs)\r\n",
        "  optimizer.apply_gradients(zip(grads, [model.W, model.B]))\r\n",
        "  if i % 20 == 0:\r\n",
        "    print(\"스텝 {:03d}에서 손실: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\r\n",
        "\r\n",
        "print(\"최종 손실: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\r\n",
        "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J23rsJ2Aa5aD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jej8upKguhb"
      },
      "source": [
        "객체 기반의 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrtHsv_sgwFc"
      },
      "source": [
        "x = tf.Variable(10.)\r\n",
        "checkpoint = tf.train.Checkpoint(x=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvMpjIj1gyAG"
      },
      "source": [
        "x.assign(2.)   # 변수에 새로운 값을 할당하고 저장\r\n",
        "checkpoint_path = './ckpt/'\r\n",
        "checkpoint.save('./ckpt/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP3kGQGpgzZM"
      },
      "source": [
        "x.assign(11.)  # 저장한 후에 변수 변경\r\n",
        "\r\n",
        "# 체크포인트로부터 값을 복구\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\r\n",
        "\r\n",
        "print(x)  # => 2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2vKUvzeg19b"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\r\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "  tf.keras.layers.Dense(10)\r\n",
        "])\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "checkpoint_dir = 'path/to/model_dir'\r\n",
        "if not os.path.exists(checkpoint_dir):\r\n",
        "  os.makedirs(checkpoint_dir)\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "root = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                           model=model)\r\n",
        "\r\n",
        "root.save(checkpoint_prefix)\r\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "968o91LFg4ZV"
      },
      "source": [
        "# 새 섹션"
      ]
    }
  ]
}